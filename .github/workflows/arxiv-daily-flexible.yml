name: arXiv Weekly Flexible Crawler

on:
  schedule:
    # ÊØèÂë®‰∏Ä UTC Êó∂Èó¥ 8:00 ËøêË°åÔºàÂåó‰∫¨Êó∂Èó¥ 16:00ÔºâÔºåÁà¨Âèñ‰∏ä‰∏ÄÂë®ÁöÑÊñáÁ´†
    - cron: "0 8 * * 1"
  workflow_dispatch:
    inputs:
      crawl_mode:
        description: 'Crawl mode'
        required: false
        default: 'last_week'
        type: choice
        options:
          - 'last_week'
          - 'custom_date'
      start_date:
        description: 'Start date (format: YYYY-MM-DD or today/tomorrow/yesterday or +/-N)'
        required: false
        default: 'last_monday'
        type: string
      end_date:
        description: 'End date (format: YYYY-MM-DD or today/tomorrow/yesterday or +/-N)'
        required: false
        default: 'last_sunday'
        type: string
      force_run:
        description: 'Force run (even if no new content)'
        required: false
        default: false
        type: boolean

jobs:
  crawl:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4

    - name: Install dependencies
      run: |
        curl -LsSf https://astral.sh/uv/install.sh | sh
        uv sync

    - name: Set date variables
      id: date_setup
      run: |
        # ËÆæÁΩÆÊó•ÊúüËåÉÂõ¥
        if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
          # ÊâãÂä®Ëß¶Âèë
          if [ "${{ github.event.inputs.crawl_mode }}" = "last_week" ]; then
            # ËÆ°ÁÆó‰∏ä‰∏ÄÂë®ÁöÑËåÉÂõ¥ÔºàÂë®‰∏ÄÂà∞Âë®Êó•Ôºâ
            START_DATE="last_monday"
            END_DATE="last_sunday"
          else
            # Ëá™ÂÆö‰πâÊó•ÊúüËåÉÂõ¥
            START_DATE="${{ github.event.inputs.start_date }}"
            END_DATE="${{ github.event.inputs.end_date }}"
          fi
        else
          # ÂÆöÊó∂Ëß¶ÂèëÔºàÊØèÂë®‰∏ÄÔºâÔºåÁà¨Âèñ‰∏ä‰∏ÄÂë®
          START_DATE="last_monday"
          END_DATE="last_sunday"
        fi
        
        # ÁîüÊàêÊñá‰ª∂Âêç
        if [ "$START_DATE" = "$END_DATE" ]; then
          FILENAME="${START_DATE}.jsonl"
        else
          FILENAME="${START_DATE}_to_${END_DATE}.jsonl"
        fi
        
        echo "start_date=$START_DATE" >> $GITHUB_OUTPUT
        echo "end_date=$END_DATE" >> $GITHUB_OUTPUT
        echo "filename=$FILENAME" >> $GITHUB_OUTPUT
        
        echo "üìÖ Crawl date range: $START_DATE to $END_DATE"
        echo "üìÑ Output filename: data/$FILENAME"

    - name: Crawl arXiv papers
      id: crawl_step
      run: |
        source .venv/bin/activate

        START_DATE="${{ steps.date_setup.outputs.start_date }}"
        END_DATE="${{ steps.date_setup.outputs.end_date }}"
        FILENAME="${{ steps.date_setup.outputs.filename }}"

        # Check if file exists
        if [ -f "data/${FILENAME}" ]; then
            echo "üóëÔ∏è Found existing data file, removing and regenerating..."
            rm "data/${FILENAME}"
        fi

        cd daily_arxiv
        export OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}
        export OPENAI_BASE_URL=${{ secrets.OPENAI_BASE_URL }}
        export LANGUAGE="${{ vars.LANGUAGE }}"
        export KEYWORDS="${{ vars.KEYWORDS }}"
        export MODEL_NAME="${{ vars.MODEL_NAME }}"
        export START_DATE="$START_DATE"
        export END_DATE="$END_DATE"
        export PER_PAGE="${{ vars.PER_PAGE || '200' }}"
        export MAX_PAGES="${{ vars.MAX_PAGES || '10' }}"
        export MAX_PAPERS="${{ vars.MAX_PAPERS || '50' }}"
        export DATE_FIELD="${{ vars.DATE_FIELD || 'published' }}"

        echo "üîç Starting arXiv paper crawling..."
        echo "üìä Keywords: $KEYWORDS"
        echo "üìÖ Date range: $START_DATE to $END_DATE"

        # Call flexible crawler
        scrapy crawl arxiv_flexible -a start_date="$START_DATE" -a end_date="$END_DATE" -o ../data/${FILENAME}

        if [ ! -f "../data/${FILENAME}" ]; then
            echo "‚ùå Crawling failed, no data file generated"
            exit 1
        fi

        # Check if file is empty
        if [ ! -s "../data/${FILENAME}" ]; then
            echo "‚ö†Ô∏è No papers found in target date range with OR logic"
            echo "üìä Keywords used: $KEYWORDS"
            echo "üìÖ Date range: $START_DATE to $END_DATE"
            echo "‚ÑπÔ∏è This might indicate that the specific week has no papers matching any of the keywords"
            echo "crawl_success=false" >> $GITHUB_OUTPUT
            echo "crawl_filename=${FILENAME}" >> $GITHUB_OUTPUT
            exit 0
        fi

        echo "crawl_success=true" >> $GITHUB_OUTPUT
        echo "crawl_filename=${FILENAME}" >> $GITHUB_OUTPUT
        echo "‚úÖ Crawling completed: ${FILENAME}"

    - name: Check for duplicates
      if: steps.crawl_step.outputs.crawl_success == 'true'
      id: dedup_check
      run: |
        source .venv/bin/activate
        echo "Performing deduplication check..."

        cd daily_arxiv
        python daily_arxiv/check_stats.py
        dedup_exit_code=$?

        echo "dedup_exit_code=$dedup_exit_code" >> $GITHUB_OUTPUT

        case $dedup_exit_code in
          0)
            echo "has_new_content=true" >> $GITHUB_OUTPUT ;;
          1)
            echo "has_new_content=false" >> $GITHUB_OUTPUT
            echo "skip_reason=no_new_content" >> $GITHUB_OUTPUT ;;
          2)
            echo "has_new_content=false" >> $GITHUB_OUTPUT
            echo "skip_reason=processing_error" >> $GITHUB_OUTPUT
            exit 1 ;;
          *)
            echo "has_new_content=false" >> $GITHUB_OUTPUT
            echo "skip_reason=unknown_error" >> $GITHUB_OUTPUT
            exit 1 ;;
        esac

    - name: AI Enhancement Processing
      if: steps.crawl_step.outputs.crawl_success == 'true' && (steps.dedup_check.outputs.has_new_content == 'true' || github.event.inputs.force_run == 'true')
      run: |
        source .venv/bin/activate
        filename=${{ steps.crawl_step.outputs.crawl_filename }}

        echo "ü§ñ Starting AI enhancement processing..."
        cd ai
        export OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}
        export OPENAI_BASE_URL=${{ secrets.OPENAI_BASE_URL }}
        export LANGUAGE="${{ vars.LANGUAGE }}"
        export MODEL_NAME="${{ vars.MODEL_NAME }}"

        python enhance.py --data ../data/${filename}

        echo "‚úÖ AI enhancement processing completed"

    - name: Convert to Markdown
      if: steps.crawl_step.outputs.crawl_success == 'true' && (steps.dedup_check.outputs.has_new_content == 'true' || github.event.inputs.force_run == 'true')
      run: |
        source .venv/bin/activate
        filename=${{ steps.crawl_step.outputs.crawl_filename }}
        export LANGUAGE="${{ vars.LANGUAGE }}"

        cd to_md
        AI_FILE="../data/${filename%.*}_AI_enhanced_${LANGUAGE}.jsonl"

        if [ -f "$AI_FILE" ]; then
          echo "üìù Converting using AI enhanced file..."
          python convert.py --data "$AI_FILE"
        else
          echo "Error: AI enhanced file not found"
          exit 1
        fi

    - name: Update file list
      if: steps.crawl_step.outputs.crawl_success == 'true' && (steps.dedup_check.outputs.has_new_content == 'true' || github.event.inputs.force_run == 'true')
      run: |
        echo "üìã Updating file list..."
        ls data/*.jsonl | sed 's|data/||' > assets/file-list.txt

    - name: Commit & Push
      if: steps.crawl_step.outputs.crawl_success == 'true' && (steps.dedup_check.outputs.has_new_content == 'true' || github.event.inputs.force_run == 'true')
      run: |
        git config --global user.email "${{ vars.EMAIL }}"
        git config --global user.name "${{ vars.NAME }}"
        git add .
        if git diff --staged --quiet; then
          echo "No changes to commit"
          exit 0
        fi
        
        START_DATE="${{ steps.date_setup.outputs.start_date }}"
        END_DATE="${{ steps.date_setup.outputs.end_date }}"
        
        if [ "$START_DATE" = "$END_DATE" ]; then
          COMMIT_MSG="weekly update: $START_DATE arXiv papers"
        else
          COMMIT_MSG="weekly update: $START_DATE to $END_DATE arXiv papers"
        fi
        
        git commit -m "$COMMIT_MSG"
        git push origin main

    - name: Summary
      run: |
        if [ "${{ steps.crawl_step.outputs.crawl_success }}" = "true" ]; then
          if [ "${{ steps.dedup_check.outputs.has_new_content }}" = "true" ] || [ "${{ github.event.inputs.force_run }}" = "true" ]; then
            echo "‚úÖ Crawling workflow completed with new content"
          else
            echo "‚ÑπÔ∏è Crawling completed but no new content, skipping update"
          fi
        else
          echo "‚ö†Ô∏è Crawling completed but no matching papers found"
        fi
